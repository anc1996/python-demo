#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Wagtail-AI æºä»£ç è¿½è¸ªå·¥å…·
å¸®åŠ©ç†è§£ AITitleFieldPanel å’Œ RichTextBlock çš„ä¸åŒè°ƒç”¨è·¯å¾„
"""

import os
import sys
import django

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'wagtail_ai_demo.settings.dev')
django.setup()

import inspect
from pathlib import Path


def print_header(title):
	print("\n" + "=" * 80)
	print(f"  {title}")
	print("=" * 80)


def show_function_source(func, name=None):
	"""æ˜¾ç¤ºå‡½æ•°æºä»£ç """
	if name is None:
		name = func.__name__
	
	print(f"\nğŸ“„ {name} æºä»£ç :")
	print(f"   ä½ç½®: {inspect.getfile(func)}:{inspect.getsourcelines(func)[1]}")
	print("-" * 80)
	try:
		source = inspect.getsource(func)
		# åªæ˜¾ç¤ºå‰50è¡Œï¼Œé¿å…å¤ªé•¿
		lines = source.split('\n')[:50]
		for i, line in enumerate(lines, 1):
			print(f"{i:3d} | {line}")
		if len(source.split('\n')) > 50:
			print(f"... (è¿˜æœ‰ {len(source.split('\n')) - 50} è¡Œ)")
	except Exception as e:
		print(f"   æ— æ³•è·å–æºä»£ç : {e}")


def trace_call_chain():
	"""è¿½è¸ªè°ƒç”¨é“¾"""
	print_header("è°ƒç”¨é“¾è¿½è¸ª")
	
	print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AITitleFieldPanel / AIDescriptionFieldPanel è°ƒç”¨é“¾          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ç”¨æˆ·ç‚¹å‡» AI æŒ‰é’® (å‰ç«¯)
   â†“
2. å‘é€ AJAX è¯·æ±‚åˆ° /admin/ai/basic_prompt/
   â†“
3. BasicPromptView.post()
   æ–‡ä»¶: wagtail_ai/views/basic_prompt.py
   â†“
4. BasicPromptAgent.execute()
   æ–‡ä»¶: wagtail_ai/agents/basic_prompt.py
   â†“
5. get_llm_service(alias='default')  â† è¿™é‡Œéœ€è¦ PROVIDERS
   æ–‡ä»¶: wagtail_ai/agents/base.py
   â†“
6. get_provider('default')
   æ–‡ä»¶: wagtail_ai/agents/base.py
   è¯»å–: settings.WAGTAIL_AI['PROVIDERS']['default']
   â†“
7. LLMService.create(**provider_config)
   æ–‡ä»¶: django_ai_core/llm/base.py
   â†“
8. AnyLLM.create(provider='deepseek', ...)
   æ–‡ä»¶: any_llm/any_llm.py
   â†“
9. åˆ›å»º DeepSeekProvider å®ä¾‹
   éœ€è¦: api_key, api_base, model


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RichTextBlock(features=['ai']) è°ƒç”¨é“¾                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ç”¨æˆ·åœ¨ Draftail ç¼–è¾‘å™¨ä¸­é€‰ä¸­æ–‡å­—ï¼Œç‚¹å‡» AI æŒ‰é’®
   â†“
2. å‘é€è¯·æ±‚åˆ°åç«¯ AI æ¥å£
   â†“
3. get_ai_backend('default')  â† è¿™é‡Œéœ€è¦ BACKENDS
   æ–‡ä»¶: wagtail_ai/ai/base.py
   è¯»å–: settings.WAGTAIL_AI['BACKENDS']['default']
   â†“
4. å®ä¾‹åŒ– OpenAICompatibleBackend
   æ–‡ä»¶: blog/ai_backends.py (ä½ çš„è‡ªå®šä¹‰åç«¯)
   â†“
5. OpenAICompatibleBackend.chat_completions()
   ç›´æ¥è°ƒç”¨ DeepSeek API
    """)


def show_key_files():
	"""æ˜¾ç¤ºå…³é”®æ–‡ä»¶"""
	print_header("å…³é”®æºä»£ç æ–‡ä»¶")
	
	try:
		import wagtail_ai.agents.base
		import wagtail_ai.agents.basic_prompt
		import wagtail_ai.ai.base
		import wagtail_ai.panels
		
		files = {
			'get_provider & get_llm_service': wagtail_ai.agents.base.__file__,
			'BasicPromptAgent': wagtail_ai.agents.basic_prompt.__file__,
			'get_ai_backend': wagtail_ai.ai.base.__file__,
			'AITitleFieldPanel': wagtail_ai.panels.__file__,
		}
		
		print("\nğŸ“ æ–‡ä»¶ä½ç½®:")
		for desc, filepath in files.items():
			print(f"\n  {desc}:")
			print(f"    {filepath}")
			
			# æ˜¾ç¤ºæ–‡ä»¶å¼€å¤´éƒ¨åˆ†
			try:
				with open(filepath, 'r', encoding='utf-8') as f:
					lines = f.readlines()[:30]
					print("    " + "-" * 60)
					for i, line in enumerate(lines, 1):
						print(f"    {i:3d} | {line.rstrip()}")
					print("    " + "-" * 60)
			except Exception as e:
				print(f"    æ— æ³•è¯»å–æ–‡ä»¶: {e}")
	
	except Exception as e:
		print(f"\nâŒ æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {e}")


def show_critical_code():
	"""æ˜¾ç¤ºå…³é”®ä»£ç æ®µ"""
	print_header("å…³é”®ä»£ç åˆ†æ")
	
	print("\nğŸ” 1. get_provider() å‡½æ•°")
	print("   è¿™ä¸ªå‡½æ•°è´Ÿè´£ä» WAGTAIL_AI['PROVIDERS'] è¯»å–é…ç½®")
	
	try:
		from wagtail_ai.agents.base import get_provider
		show_function_source(get_provider)
	except Exception as e:
		print(f"   æ— æ³•æ˜¾ç¤º: {e}")
	
	print("\nğŸ” 2. get_llm_service() å‡½æ•°")
	print("   è¿™ä¸ªå‡½æ•°ä½¿ç”¨ get_provider() çš„ç»“æœåˆ›å»º LLM æœåŠ¡")
	
	try:
		from wagtail_ai.agents.base import get_llm_service
		show_function_source(get_llm_service)
	except Exception as e:
		print(f"   æ— æ³•æ˜¾ç¤º: {e}")
	
	print("\nğŸ” 3. get_ai_backend() å‡½æ•°")
	print("   è¿™ä¸ªå‡½æ•°ä» WAGTAIL_AI['BACKENDS'] è¯»å–é…ç½®")
	
	try:
		from wagtail_ai.ai.base import get_ai_backend
		show_function_source(get_ai_backend)
	except Exception as e:
		print(f"   æ— æ³•æ˜¾ç¤º: {e}")


def analyze_error():
	"""åˆ†æé”™è¯¯åŸå› """
	print_header("é”™è¯¯åŸå› åˆ†æ")
	
	print("""
âŒ é”™è¯¯ä¿¡æ¯:
   any_llm.exceptions.MissingApiKeyError:
   No openai API key provided. Please provide it in the config
   or set the OPENAI_API_KEY environment variable.

ğŸ” é”™è¯¯åŸå› :
   1. AITitleFieldPanel è°ƒç”¨ get_llm_service()
   2. get_llm_service() è°ƒç”¨ get_provider('default')
   3. get_provider() åœ¨ WAGTAIL_AI['PROVIDERS'] ä¸­æ‰¾ä¸åˆ° 'default'
   4. ç³»ç»Ÿ fallback åˆ° 'openai' provider (ç¡¬ç¼–ç çš„é»˜è®¤å€¼)
   5. any_llm å°è¯•åˆ›å»º OpenAI provider
   6. ä½†æ˜¯æ²¡æœ‰ OPENAI_API_KEY ç¯å¢ƒå˜é‡ â†’ æŠ¥é”™

ğŸ“Š è°ƒç”¨æ ˆéªŒè¯:
   File "wagtail_ai/agents/base.py", line 81, in get_llm_service
     return LLMService.create(**get_provider(alias))
                              ^^^^^^^^^^^^^^^^^^^
   è¿™é‡Œè°ƒç”¨äº† get_provider()

   File "any_llm/any_llm.py", line 99, in _verify_and_set_api_key
     raise MissingApiKeyError(self.PROVIDER_NAME, self.ENV_API_KEY_NAME)
   any_llm æœŸæœ›çš„æ˜¯ 'openai' providerï¼Œä½†æ²¡æœ‰å¯¹åº”çš„ API key

âœ… è§£å†³æ–¹æ¡ˆ:
   åœ¨ WAGTAIL_AI é…ç½®ä¸­æ·»åŠ  PROVIDERS éƒ¨åˆ†:

   WAGTAIL_AI = {
       "PROVIDERS": {
           "default": {
               "provider": "deepseek",  # â† å…³é”®ï¼šæŒ‡å®š provider
               "model": "deepseek-chat",
               "api_key": os.getenv("DEEPSEEK_API_KEY"),
               "api_base": os.getenv("DEEPSEEK_BASE_URL"),
           }
       },
       "BACKENDS": {
           # ... ä¿æŒä¸å˜
       },
   }

ğŸ’¡ ä¸ºä»€ä¹ˆ RichTextBlock èƒ½ç”¨ï¼Ÿ
   å› ä¸º RichTextBlock(features=['ai']) ä½¿ç”¨çš„æ˜¯:
   - get_ai_backend() â†’ è¯»å– BACKENDS é…ç½®
   - ä½ å·²ç»é…ç½®äº† BACKENDSï¼Œæ‰€ä»¥èƒ½æ­£å¸¸å·¥ä½œ

   è€Œ AITitleFieldPanel ä½¿ç”¨çš„æ˜¯:
   - get_llm_service() â†’ è¯»å– PROVIDERS é…ç½®
   - ä½ æ²¡æœ‰é…ç½® PROVIDERSï¼Œæ‰€ä»¥å¤±è´¥
    """)


def main():
	"""ä¸»å‡½æ•°"""
	print("\n" + "ğŸ”" * 40)
	print("  Wagtail-AI æºä»£ç è¿½è¸ªå·¥å…·")
	print("ğŸ”" * 40)
	
	# 1. è°ƒç”¨é“¾è¿½è¸ª
	trace_call_chain()
	
	# 2. æ˜¾ç¤ºå…³é”®æ–‡ä»¶
	show_key_files()
	
	# 3. æ˜¾ç¤ºå…³é”®ä»£ç 
	show_critical_code()
	
	# 4. é”™è¯¯åˆ†æ
	analyze_error()
	
	print_header("æ€»ç»“")
	print("""
ğŸ“ é—®é¢˜å®šä½å®Œæˆï¼

æ ¸å¿ƒé—®é¢˜ï¼š
  é…ç½®ä¸­ç¼ºå°‘ PROVIDERS éƒ¨åˆ†ï¼Œå¯¼è‡´ AITitleFieldPanel å¤±è´¥

è§£å†³æ­¥éª¤ï¼š
  1. è¿è¡Œè°ƒè¯•è„šæœ¬ç¡®è®¤é—®é¢˜ï¼š
     python debug_wagtail_ai.py

  2. åº”ç”¨ä¿®å¤é…ç½®ï¼š
     å¤åˆ¶ fixed_settings.py ä¸­çš„é…ç½®åˆ° base.py

  3. é‡å¯æœåŠ¡å™¨æµ‹è¯•ï¼š
     python manage.py runserver 0.0.0.0:8000

  4. å¦‚éœ€æ·±å…¥è°ƒè¯•ï¼Œä½¿ç”¨äº¤äº’å¼å·¥å…·ï¼š
     python debug_interactive.py

     ç„¶ååœ¨äº¤äº’å¼ç¯å¢ƒä¸­è¿è¡Œï¼š
     >>> test_provider()  # æµ‹è¯• PROVIDERS é…ç½®
     >>> test_backend()   # æµ‹è¯• BACKENDS é…ç½®
    """)


if __name__ == "__main__":
	main()